{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fever_data = '/home/ashrafs/projects/dragon/data/fever/enriched_feverous_dev.jsonl'\n",
    "\n",
    "train_fever_data = '/home/ashrafs/projects/dragon/data/fever/statement/train.statement.jsonl'\n",
    "test_fever_data = '/home/ashrafs/projects/dragon/data/fever/statement/test.statement.jsonl'\n",
    "dev_fever_data = '/home/ashrafs/projects/dragon/data/fever/statement/dev.statement.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fever_graph = '/home/ashrafs/projects/dragon/data/fever/graph/train_graph.pickle'\n",
    "test_fever_graph = '/home/ashrafs/projects/dragon/data/fever/graph/test_graph.pickle'\n",
    "dev_fever_graph = '/home/ashrafs/projects/dragon/data/fever/graph/dev_graph.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "# Load the data\n",
    "data_list = load_data(all_fever_data)\n",
    "\n",
    "# Now, data_list contains all the data from the JSONL file\n",
    "# Count the claims\n",
    "number_of_claims = len(data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7890"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_statements_per_claim(data_list):\n",
    "    claim_data = []\n",
    "    for data in data_list:\n",
    "        claim_text = data.get('CLAIM', 'No Claim Found')\n",
    "        entity_statements = data.get('ENTITY_STATEMENTS', {})\n",
    "\n",
    "        # Count the number of statements for the current claim\n",
    "        statement_count = sum(len(details.get('statements', [])) for _, details in entity_statements.items()) if entity_statements is not None else 0\n",
    "\n",
    "        # Store both the claim text and the count in a tuple\n",
    "        claim_data.append((claim_text, statement_count))\n",
    "\n",
    "    return claim_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming data_list contains your loaded data\n",
    "claim_data = count_statements_per_claim(data_list)\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(claim_data, columns=['Claim', 'Statement Counts'])\n",
    "\n",
    "# Now df contains both the claim text and the corresponding statement counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claims with Non-Zero Statements:\n",
      "5395\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to get rows where 'Statement Counts' is 0\n",
    "claims_with_statements = df[df['Statement Counts'] > 0]\n",
    "\n",
    "# Display these claims\n",
    "print(\"Claims with Non-Zero Statements:\")\n",
    "print(len(claims_with_statements['Claim']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_list = [\n",
    "    data for data in data_list \n",
    "    if data.get('ENTITY_STATEMENTS') is not None and \n",
    "       sum(len(details.get('statements', [])) for _, details in data.get('ENTITY_STATEMENTS', {}).items()) >= 10\n",
    "]\n",
    "\n",
    "# Splitting data_list into train, test, and dev sets (10 elements each)\n",
    "train_data = filtered_data_list[:10]\n",
    "test_data = filtered_data_list[10:20]\n",
    "dev_data = filtered_data_list[20:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_fully_connected(G):\n",
    "    return nx.is_connected(G.to_undirected()) if G.number_of_nodes() > 1 else False\n",
    "\n",
    "def construct_graphs(data_subset, pickle_file_path):\n",
    "    graphs_stats = []\n",
    "    max_nodes = 200  # Maximum number of nodes allowed\n",
    "\n",
    "    for data in data_subset:\n",
    "        G = nx.DiGraph()  # Using a directed graph\n",
    "        entity_statements = data.get('ENTITY_STATEMENTS', {})\n",
    "\n",
    "        for _, details in entity_statements.items():\n",
    "            for statement in details.get('statements', []):\n",
    "                subject, relation, obj = statement\n",
    "                # Check if the current number of nodes is less than the maximum allowed\n",
    "                if G.number_of_nodes() < max_nodes:\n",
    "                    # Add edge with relation as an edge attribute\n",
    "                    G.add_edge(subject, obj, relation=relation)\n",
    "                else:\n",
    "                    break  # Stop adding edges/nodes once the maximum number is reached\n",
    "\n",
    "        num_nodes = G.number_of_nodes()\n",
    "        fully_connected = is_fully_connected(G)\n",
    "        \n",
    "        graphs_stats.append({'Claim': data.get('CLAIM'), 'Num_Nodes': num_nodes, 'Is_Fully_Connected': fully_connected, 'Graph': G})\n",
    "\n",
    "    # Save the list of graphs to a file\n",
    "    with open(pickle_file_path, \"wb\") as f:\n",
    "        pickle.dump(graphs_stats, f)\n",
    "\n",
    "# Example usage\n",
    "construct_graphs(train_data, train_fever_graph)\n",
    "construct_graphs(test_data, test_fever_graph)\n",
    "construct_graphs(dev_data, dev_fever_graph)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 ('dragon2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08587c0f5c67a3495a6970ba7d5b464d0115ad99415726a58f65952f34bfe0bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
